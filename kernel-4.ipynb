{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis Project by Mohamed Alaa Gaida and Nadine Fakhet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "f1bb0df276cf20131ea03075d2243d28843ffd2e"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "7f7b26518aef4c074f01a6f34982c020365378e5"
   },
   "outputs": [],
   "source": [
    "path = \"training.1600000.processed.noemoticon.csv\"\n",
    "data = pd.read_csv(path, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "3fdfbb11b954f544db35d4f84f030f339034d671"
   },
   "outputs": [],
   "source": [
    "data.columns = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
    "data = data.drop([\"id\", \"date\", \"query\", \"user\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "c183b1a350340178832f68fa5101a5ca6f8627ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  is upset that he can't update his Facebook by ...\n",
       "1          0  @Kenichan I dived many times for the ball. Man...\n",
       "2          0    my whole body feels itchy and like its on fire \n",
       "3          0  @nationwideclass no, it's not behaving at all....\n",
       "4          0                      @Kwesidei not the whole crew "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7a02880a4c2e5870a12832f96a038f32ab829f6f"
   },
   "outputs": [],
   "source": [
    "y = data.sentiment\n",
    "X = data.text\n",
    "y = y/4\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "0dec928a982861724a2fa497b057953acfae08fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1279999,)\n",
      "(1279999,)\n",
      "(320000,)\n",
      "(320000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "1206d9adf3620ec84c44c3bd6d503deb8b05b736"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocabulary = 100000\n",
    "tokenizer = Tokenizer(num_words=vocabulary)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "180b8f13279067018227efdf737ea1b2d4d9f559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just ate dinner... at 11pm. And now I'm in bed thinking about stuff. \n",
      "i had something really good to post earlier... just cant remember what it was now \n",
      "@nyc_paris Well... My Uncle Allen thinks I need help \n",
      "@BrookeAdamsTBG5 congrats on the win. cant wait to see you this summer ! miss you so much \n",
      "Oh hell...I'm 30 today. \n"
     ]
    }
   ],
   "source": [
    "for x in X_train[:5]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "1131adae5bcd9aa910e903943a16f25bd99f6650"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 714, 383, 23, 4877, 6, 27, 19, 11, 141, 398, 61, 293],\n",
       " [1, 66, 208, 63, 28, 2, 471, 843, 20, 171, 515, 55, 9, 25, 27],\n",
       " [1123, 1572, 74, 5, 2086, 3154, 873, 1, 93, 241],\n",
       " [51857, 634, 13, 3, 440, 171, 143, 2, 68, 7, 26, 238, 88, 7, 15, 89],\n",
       " [83, 479, 19, 443, 41]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "60449532f28fc5f10990d75549472a98ba4fba47"
   },
   "outputs": [],
   "source": [
    "length = []\n",
    "for x in X_train:\n",
    "    length.append(len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "f6be75aa5c0b5986e9f6ba282fa9d3385d613256"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "58da173e056faa55e5932e08a0854ae42b65de90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.176499356640122"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sum(length)/len(length)\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "4ffea3dbbfa9d72af37757113adb71036af2ae79"
   },
   "outputs": [],
   "source": [
    "LEN = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "4c687b31b20d68ef965e97457119d24c573399d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1279999, 32)\n"
     ]
    }
   ],
   "source": [
    "x_train_seq = pad_sequences(sequences, maxlen=LEN)       \n",
    "x_train_seq = np.matrix(x_train_seq)\n",
    "print('Shape of data tensor:', x_train_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "967f28f6111e2e530b6903562d594d910af6ba7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,    20,   714,   383,    23,  4877,     6,    27,    19,\n",
       "            11,   141,   398,    61,   293],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     1,\n",
       "            66,   208,    63,    28,     2,   471,   843,    20,   171,\n",
       "           515,    55,     9,    25,    27],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,  1123,  1572,    74,     5,  2086,\n",
       "          3154,   873,     1,    93,   241],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0, 51857,   634,\n",
       "            13,     3,   440,   171,   143,     2,    68,     7,    26,\n",
       "           238,    88,     7,    15,    89],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            83,   479,    19,   443,    41]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "05b0bed79ca0678949d1105a109d85f4fbc5156d"
   },
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "9ab66e8edd5461ae14d3ef8244439bc442f152cb"
   },
   "outputs": [],
   "source": [
    "hidden_size = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "21f81e52c36fbcd73e6ef38ecc6dd21d307129aa"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "b54369ad4c72f2b9b3b696c476f2b84363737015"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary, hidden_size, input_length=LEN))\n",
    "model.add(LSTM(1, return_sequences=False))\n",
    "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "3dc74c09fc285a9c17e29c70e3d619625781a629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 32, 192)           19200000  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1)                 776       \n",
      "=================================================================\n",
      "Total params: 19,200,776\n",
      "Trainable params: 19,200,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "f4ead574e8ffc4e65cbed1253403ede58cb45f98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1279999 samples, validate on 320000 samples\n",
      "Epoch 1/5\n",
      "1279999/1279999 [==============================] - 7349s 6ms/step - loss: 0.1423 - acc: 0.7995 - val_loss: 0.1363 - val_acc: 0.8083\n",
      "Epoch 2/5\n",
      "1279999/1279999 [==============================] - 6973s 5ms/step - loss: 0.1296 - acc: 0.8195 - val_loss: 0.1362 - val_acc: 0.8086\n",
      "Epoch 3/5\n",
      "1279999/1279999 [==============================] - 7098s 6ms/step - loss: 0.1251 - acc: 0.8265 - val_loss: 0.1374 - val_acc: 0.8068\n",
      "Epoch 4/5\n",
      "1279999/1279999 [==============================] - 11394s 9ms/step - loss: 0.1221 - acc: 0.8311 - val_loss: 0.1362 - val_acc: 0.8095\n",
      "Epoch 5/5\n",
      "1279999/1279999 [==============================] - 7117s 6ms/step - loss: 0.1200 - acc: 0.8347 - val_loss: 0.1377 - val_acc: 0.8072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8dd984f28>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epoch = 5\n",
    "batch_size = 64\n",
    "model.fit(x_train_seq, y_train, validation_data=(x_test_seq, y_test), epochs=n_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('myModel.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('myModel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the architecture :\n",
    "Adding 2 more LSTM Layers and changing the optimizer to RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(vocabulary, hidden_size, input_length=LEN))\n",
    "model2.add(LSTM(hidden_size, return_sequences=True))\n",
    "model2.add(LSTM(hidden_size//2, return_sequences=True))\n",
    "model2.add(LSTM(1, return_sequences=False))\n",
    "opt2 = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "model2.compile(loss='mean_squared_error', optimizer=opt2, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 32, 192)           19200000  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32, 192)           295680    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32, 96)            110976    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1)                 392       \n",
      "=================================================================\n",
      "Total params: 19,607,048\n",
      "Trainable params: 19,607,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1279999 samples, validate on 320000 samples\n",
      "Epoch 1/5\n",
      "1279999/1279999 [==============================] - 4569s 4ms/step - loss: 0.1315 - acc: 0.8129 - val_loss: 0.1212 - val_acc: 0.8282\n",
      "Epoch 2/5\n",
      "1279999/1279999 [==============================] - 4567s 4ms/step - loss: 0.1136 - acc: 0.8412 - val_loss: 0.1176 - val_acc: 0.8350\n",
      "Epoch 3/5\n",
      "1279999/1279999 [==============================] - 4590s 4ms/step - loss: 0.1056 - acc: 0.8538 - val_loss: 0.1175 - val_acc: 0.8359\n",
      "Epoch 4/5\n",
      "1279999/1279999 [==============================] - 4451s 3ms/step - loss: 0.0992 - acc: 0.8639 - val_loss: 0.1182 - val_acc: 0.8358\n",
      "Epoch 5/5\n",
      "1279999/1279999 [==============================] - 4436s 3ms/step - loss: 0.0934 - acc: 0.8730 - val_loss: 0.1199 - val_acc: 0.8327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8f3927fc88>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epoch = 5\n",
    "batch_size = 64\n",
    "model2.fit(x_train_seq, y_train, validation_data=(x_test_seq, y_test), epochs=n_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save_weights('myModel2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('myModel2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the architecture :\n",
    "changing the learining rate and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Embedding(vocabulary, hidden_size, input_length=LEN))\n",
    "model3.add(LSTM(hidden_size, return_sequences=True))\n",
    "model3.add(LSTM(hidden_size//2, return_sequences=True))\n",
    "model3.add(LSTM(1, return_sequences=False))\n",
    "opt3 = keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0)\n",
    "model3.compile(loss='mean_squared_error', optimizer=opt2, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1279999 samples, validate on 320000 samples\n",
      "Epoch 1/2\n",
      "1279999/1279999 [==============================] - 8913s 7ms/step - loss: 0.1317 - acc: 0.8129 - val_loss: 0.1232 - val_acc: 0.8273\n",
      "Epoch 2/2\n",
      "1279999/1279999 [==============================] - 9010s 7ms/step - loss: 0.1165 - acc: 0.8375 - val_loss: 0.1203 - val_acc: 0.8312\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 2\n",
    "batch_size = 32\n",
    "model3.fit(x_train_seq, y_train, validation_data=(x_test_seq, y_test), epochs=2, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save_weights('myModel3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.load_weights('myModel3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 : acc: 80.72%\n",
      "Model 2 : acc: 83.27%\n",
      "Model 3 : acc: 83.12%\n"
     ]
    }
   ],
   "source": [
    "scores1 = model.evaluate(x_test_seq, y_test, verbose=0)\n",
    "print(\"Model 1 : %s: %.2f%%\" % (model.metrics_names[1], scores1[1]*100))\n",
    "\n",
    "scores2 = model2.evaluate(x_test_seq, y_test, verbose=0)\n",
    "print(\"Model 2 : %s: %.2f%%\" % (model2.metrics_names[1], scores2[1]*100))\n",
    "\n",
    "scores3 = model3.evaluate(x_test_seq, y_test, verbose=0)\n",
    "print(\"Model 3 : %s: %.2f%%\" % (model3.metrics_names[1], scores3[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\" I love cats \"]\n",
    "x2 = tokenizer.texts_to_sequences(x)\n",
    "x3 = pad_sequences(x2, maxlen=32)\n",
    "\n",
    "s1 = model.predict(x3, verbose=2)\n",
    "s2 = model2.predict(x3, verbose=2)\n",
    "s3 = model3.predict(x3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 :  86.85%\n",
      "Model 2 :  90.81%\n",
      "Model 3 :  87.70%\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1 :  %.2f%%\" % (s1[0][0]*100))\n",
    "print(\"Model 2 :  %.2f%%\" % (s2[0][0]*100))\n",
    "print(\"Model 3 :  %.2f%%\" % (s3[0][0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
